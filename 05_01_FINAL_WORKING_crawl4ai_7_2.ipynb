{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637c1b36",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     60\u001b[39m result = subprocess.run(\n\u001b[32m     61\u001b[39m     [sys.executable, \u001b[38;5;28mstr\u001b[39m(script_path)],\n\u001b[32m     62\u001b[39m     capture_output=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     63\u001b[39m     text=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     64\u001b[39m     timeout=\u001b[32m120\u001b[39m\n\u001b[32m     65\u001b[39m )\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.returncode == \u001b[32m0\u001b[39m:\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# Parse the JSON output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     data_res = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSuccessfully crawled!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data_res[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\json\\__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\json\\decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    341\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m     end = _w(s, end).end()\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python313\\Lib\\json\\decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    361\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a temporary Python script\n",
    "script_content = '''\n",
    "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n",
    "import asyncio\n",
    "import json\n",
    "import sys\n",
    "\n",
    "urls_to_crawl = [\n",
    "    \"https://docs.llamaindex.ai/en/stable/understanding/\",\n",
    "]\n",
    "\n",
    "config = CrawlerRunConfig(\n",
    "    cache_mode=CacheMode.BYPASS,\n",
    "    page_timeout=80000,\n",
    "    word_count_threshold=50,\n",
    ")\n",
    "\n",
    "async def crawl_website():\n",
    "    data_res = {\"data\": []}\n",
    "\n",
    "    async with AsyncWebCrawler(headless=True, verbose=False) as crawler:  # Set verbose=False\n",
    "        results = await crawler.arun_many(urls_to_crawl, config=config)\n",
    "\n",
    "        for result in results:\n",
    "            if result.success:\n",
    "                title = result.metadata.get(\"title\", \"\")\n",
    "                if not title and result.markdown:\n",
    "                    lines = result.markdown.raw_markdown.split(\"\\\\n\")\n",
    "                    for line in lines:\n",
    "                        if line.startswith(\"#\"):\n",
    "                            title = line.strip(\"#\").strip()\n",
    "                            break\n",
    "\n",
    "                data_res[\"data\"].append(\n",
    "                    {\n",
    "                        \"text\": result.markdown.raw_markdown if result.markdown else \"\",\n",
    "                        \"meta\": {\"url\": result.url, \"meta\": {\"title\": title}},\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return data_res\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_res = asyncio.run(crawl_website())\n",
    "    # Write to stderr for debugging, stdout for data\n",
    "    print(json.dumps(data_res), file=sys.stdout)\n",
    "'''\n",
    "\n",
    "# Write script to temp file\n",
    "script_path = Path(\"temp_crawler.py\")\n",
    "script_path.write_text(script_content)\n",
    "\n",
    "# Run as subprocess\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, str(script_path)],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=120\n",
    "    )\n",
    "\n",
    "    if result.returncode == 0:\n",
    "        # Parse the JSON output\n",
    "        data_res = json.loads(result.stdout.strip())\n",
    "        print(\"Successfully crawled!\")\n",
    "        print(f\"Number of results: {len(data_res['data'])}\")\n",
    "        if data_res['data']:\n",
    "            print(f\"First result URL: {data_res['data'][0]['meta']['url']}\")\n",
    "            print(f\"Text length: {len(data_res['data'][0]['text'])} characters\")\n",
    "    else:\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "finally:\n",
    "    # Clean up\n",
    "    if script_path.exists():\n",
    "        script_path.unlink()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Full_Stack_Developer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
